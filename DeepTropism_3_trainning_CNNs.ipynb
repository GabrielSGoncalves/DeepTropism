{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and splitting Dataset\n",
    "The goal of this notebook is to continue the development of the DeepTropism model using a Pytorch.<br>\n",
    "The dataset was already created on the previous notebook and all the HIV-1 env V3 loop sequences where aligned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used on the analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the Dataframe with all the sequences published on referenced articles.<br>\n",
    "The D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "      <th>sequence_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B.FR.83.HXB2_LAI_IIIB_BRU.K03455</td>\n",
       "      <td>LANL</td>\n",
       "      <td>-</td>\n",
       "      <td>CTRPNNN-TRKRI-RIQRGPGRAFVTI-----GK-IGNMRQAHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A1.CD.02.LA01AlPr.KU168256</td>\n",
       "      <td>LANL</td>\n",
       "      <td>-</td>\n",
       "      <td>CIRPNNN-TRKGI-GI--GPGQTFYAA-----DAIIGNIRHAYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A1.CM.08.886_24.KP718928</td>\n",
       "      <td>LANL</td>\n",
       "      <td>-</td>\n",
       "      <td>CSRPNNN-TRRSI-RI--GPGQSFYAT-----GEIIGDIREARC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A1.ES.15.100_117.KY496622</td>\n",
       "      <td>LANL</td>\n",
       "      <td>-</td>\n",
       "      <td>CTRPGNN-TRTSI-RI--GPGQAFYAT-----GDIIGDIRKAYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A1.KE.11.DEMA111KE002.KF716474</td>\n",
       "      <td>LANL</td>\n",
       "      <td>-</td>\n",
       "      <td>CTRPNNN-TRKSV-RI--GPGQAFFAT-----GEVIGKIRKAYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           seq_name dataset label  \\\n",
       "0  B.FR.83.HXB2_LAI_IIIB_BRU.K03455    LANL     -   \n",
       "1        A1.CD.02.LA01AlPr.KU168256    LANL     -   \n",
       "2          A1.CM.08.886_24.KP718928    LANL     -   \n",
       "3         A1.ES.15.100_117.KY496622    LANL     -   \n",
       "4    A1.KE.11.DEMA111KE002.KF716474    LANL     -   \n",
       "\n",
       "                               sequence_aligned  \n",
       "0  CTRPNNN-TRKRI-RIQRGPGRAFVTI-----GK-IGNMRQAHC  \n",
       "1  CIRPNNN-TRKGI-GI--GPGQTFYAA-----DAIIGNIRHAYC  \n",
       "2  CSRPNNN-TRRSI-RI--GPGQSFYAT-----GEIIGDIREARC  \n",
       "3  CTRPGNN-TRTSI-RI--GPGQAFYAT-----GDIIGDIRKAYC  \n",
       "4  CTRPNNN-TRKSV-RI--GPGQAFFAT-----GEVIGKIRKAYC  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/gabriel/Documents/Repos/DeepTropism/datasets/dataset_profile_final.tsv', \n",
    "                 sep='\\t', names=['seq_name', 'dataset', 'label', 'sequence_aligned'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9748, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check the size of the column of the alig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{44}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['sequence_aligned'].apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the original datasets present on Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newdb         2998\n",
       "cm            2679\n",
       "hivcopred     2335\n",
       "geno2pheno    1188\n",
       "webpssm        350\n",
       "LANL           198\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9748, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.label != 'validation']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCR5     7705\n",
       "CXCR4     937\n",
       "R5X4      908\n",
       "-         198\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label_numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d57a756b9d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deeptropism/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label_numeric'"
     ]
    }
   ],
   "source": [
    "df.label_numeric.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the dataset by unique sequences\n",
    "To improve the quality of our trainning and avoid bias we are going to create a dataset with only unique sequences from the original Dataframe.\n",
    "This is going to be the dataset for the development of our model based on Deep Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['sequence_aligned'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "      <th>sequence_aligned</th>\n",
       "      <th>label_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RAB014775</td>\n",
       "      <td>newdb</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>CTRPSNNTRTGITIGPGQVWYRTGDIIGDIRKAYC</td>\n",
       "      <td>CTRPSNNT-RTGI---T--I--G-P--G--Q-VWY---R-T--GDI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RAB014776</td>\n",
       "      <td>newdb</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>CTRPSNNTRTSITIGPGQVWYRTGDIIGDIRQAYC</td>\n",
       "      <td>CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RAB014778</td>\n",
       "      <td>newdb</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>CTRPSNNTRTSITIGPGQVWYRTGDIIGDIRKAYC</td>\n",
       "      <td>CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RAB014781</td>\n",
       "      <td>newdb</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>CTRPSNNTRTSVTIGPGQVWYRTGDIIGDIRQAYC</td>\n",
       "      <td>CTRPSNNT-RTSV---T--I--G-P--G--Q-VWY---R-T--GDI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RAB014834</td>\n",
       "      <td>newdb</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>CTRPSNNTRTSITIGPGQVWYRTGDIIGNIRKAYC</td>\n",
       "      <td>CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq_name dataset label                             sequence  \\\n",
       "0  RAB014775   newdb  CCR5  CTRPSNNTRTGITIGPGQVWYRTGDIIGDIRKAYC   \n",
       "1  RAB014776   newdb  CCR5  CTRPSNNTRTSITIGPGQVWYRTGDIIGDIRQAYC   \n",
       "2  RAB014778   newdb  CCR5  CTRPSNNTRTSITIGPGQVWYRTGDIIGDIRKAYC   \n",
       "3  RAB014781   newdb  CCR5  CTRPSNNTRTSVTIGPGQVWYRTGDIIGDIRQAYC   \n",
       "4  RAB014834   newdb  CCR5  CTRPSNNTRTSITIGPGQVWYRTGDIIGNIRKAYC   \n",
       "\n",
       "                                    sequence_aligned  label_numeric  \n",
       "0  CTRPSNNT-RTGI---T--I--G-P--G--Q-VWY---R-T--GDI...              0  \n",
       "1  CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...              0  \n",
       "2  CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...              0  \n",
       "3  CTRPSNNT-RTSV---T--I--G-P--G--Q-VWY---R-T--GDI...              0  \n",
       "4  CTRPSNNT-RTSI---T--I--G-P--G--Q-VWY---R-T--GDI...              0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2783\n",
       "1     825\n",
       "Name: label_numeric, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.label_numeric.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCR5     2783\n",
       "R5X4      485\n",
       "CXCR4     340\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes for comparing performance against other methods\n",
    "In order to evaluate our model against the others already published, we are going to create separate Dataframes for each method filterinf by the 'dataset' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newdb         2998\n",
       "cm            2679\n",
       "hivcopred     2335\n",
       "geno2pheno    1188\n",
       "webpssm        350\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newdb = df[df.dataset == 'newdb']\n",
    "df_cm = df[df.dataset == 'cm']\n",
    "df_hivcopred = df[df.dataset == 'hivcopred']\n",
    "df_geno2pheno = df[df.dataset == 'geno2pheno']\n",
    "df_webpssm = df[df.dataset == 'webpssm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the Dataset for Cross Validation\n",
    "We are going to create indices and set it to variables to make our cross validation reproducible. Our dataset is going to consist on:<br>\n",
    "* Trainning = 80 %\n",
    "* Validation = 10 %\n",
    "* Test = 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of indices and shuffle it using seed\n",
    "random.seed(42)\n",
    "size = df_unique.shape[0]\n",
    "list_indices = list(range(size))\n",
    "random.shuffle(list_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the list of indices for trainning, validation and test\n",
    "test_indices = list_indices[:int(size/10)]\n",
    "train_val_indices = list_indices[int(size/10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3248"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_val_indices) + len(test_indices) == len(list_indices), \"Splitting indices with error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataloaders for trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_from_sequence(protein_sequence):\n",
    "    \"\"\"\n",
    "    Function to convert a protein sequence into a tensor.\n",
    "    Each amino acid is represented by an numpy array of zeros of size 26,\n",
    "    and the dict_aa_pos defines the position to be converted to 1.\n",
    "    \n",
    "    The function iterates over the protein sequences and stacks the arrays.\n",
    "    At the end the arrays are linearized and converted to a tensor of size\n",
    "    n x 26, with n the size of the protein.\n",
    "    \n",
    "    If the character is not present on the dict_aa_pos (eg. '-') the respective\n",
    "    array is formed by zeros, and represents a missing value.\n",
    "    \"\"\"\n",
    "    dict_aa_pos = {\n",
    "    'A':1, 'R':2, 'N':3, 'D':4, 'C':5, 'Q':6, 'E':7, 'G':8,\n",
    "    'H':9, 'I':10, 'L':11, 'K':12, 'M':13, 'F':14, 'P':15, \n",
    "    'O':16, 'S':17, 'U':18, 'T':19, 'W':20, 'Y':21, 'V':22, \n",
    "    'B':23, 'Z':24, 'J':25, 'X':0}\n",
    "    \n",
    "    f_array = np.zeros(26)\n",
    "    for aa in protein_sequence:\n",
    "        arr = np.zeros(26)\n",
    "        if dict_aa_pos.get(aa):\n",
    "            arr[dict_aa_pos.get(aa)] = 1\n",
    "        f_array = np.vstack((f_array, arr))\n",
    "    f_array = np.delete(f_array, 0,0)\n",
    "    \n",
    "    #return torch.from_numpy((f_array.flatten()).astype(float))\n",
    "    return f_array.flatten().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aa_pos = {\n",
    "    'A':1, 'R':2, 'N':3, 'D':4, 'C':5, 'Q':6, 'E':7, 'G':8,\n",
    "    'H':9, 'I':10, 'L':11, 'K':12, 'M':13, 'F':14, 'P':15, \n",
    "    'O':16, 'S':17, 'U':18, 'T':19, 'W':20, 'Y':21, 'V':22, \n",
    "    'B':23, 'Z':24, 'J':25, 'X':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_aa_pos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data = []\n",
    "list_labels = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df.iterrows():\n",
    "    list_data.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels.append(int(row.label_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data) == len(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test set\n",
    "test_data = []\n",
    "test_label = []\n",
    "for j in test_indices:\n",
    "    test_data.append(list_data[j])\n",
    "    test_label.append(np.array(list_labels[j]))\n",
    "\n",
    "test_tensor_x = torch.stack([torch.from_numpy(i) for i in test_data]) # transform to torch tensors\n",
    "test_tensor_y = torch.stack([torch.from_numpy(i) for i in test_label])\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_tensor_x,test_tensor_y) # create your test dataset\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64) # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3248"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we define the\n",
    "len(train_val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_val_indices = np.array_split(train_val_indices,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crossval_val_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: 1\n",
      "Cross Validation: 2\n",
      "Cross Validation: 3\n",
      "Cross Validation: 4\n",
      "Cross Validation: 5\n"
     ]
    }
   ],
   "source": [
    "# For Trainning and validation set\n",
    "# Define the cross validation indices for trainning and validation sets\n",
    "crossval_val_indices = np.array_split(train_val_indices,5)\n",
    "\n",
    "# Iterate over crossval_val_indices defining the Dataloaders\n",
    "for n in range(len(crossval_val_indices)):\n",
    "    print(f'Cross Validation: {n + 1}')\n",
    "    trainning_data = []\n",
    "    trainning_label = []\n",
    "    validation_data = []\n",
    "    validation_label = []\n",
    "\n",
    "    validation_indices = list(crossval_val_indices[n])\n",
    "    trainning_indices = list(set(train_val_indices) - set(validation_indices))\n",
    "\n",
    "    for j in validation_indices:\n",
    "        validation_data.append(list_data[j])\n",
    "        validation_label.append(np.array(list_labels[j]))\n",
    "\n",
    "    validation_tensor_x = torch.stack([torch.from_numpy(i) for i in validation_data]) # transform to torch tensors\n",
    "    validation_tensor_y = torch.stack([torch.from_numpy(i) for i in validation_label])\n",
    "\n",
    "    validation_dataset = torch.utils.data.TensorDataset(validation_tensor_x,validation_tensor_y) # create your test dataset\n",
    "    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=64) # create your dataloader\n",
    "    \n",
    "    for k in trainning_indices:\n",
    "        trainning_data.append(list_data[k])\n",
    "        trainning_label.append(np.array(list_labels[k]))\n",
    "\n",
    "    trainning_tensor_x = torch.stack([torch.from_numpy(i) for i in trainning_data]) # transform to torch tensors\n",
    "    trainning_tensor_y = torch.stack([torch.from_numpy(i) for i in trainning_label])\n",
    "\n",
    "    trainning_dataset = torch.utils.data.TensorDataset(trainning_tensor_x,trainning_tensor_y) # create your test dataset\n",
    "    trainning_dataloader = torch.utils.data.DataLoader(trainning_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Deep Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepTropism_1(\n",
       "  (linear1): Linear(in_features=1560, out_features=250, bias=True)\n",
       "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepTropism_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepTropism_1, self).__init__()\n",
    "        self.linear1 = nn.Linear(1560,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,2)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    " \n",
    "model = DeepTropism_1().float()\n",
    "#model = model.float()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For showing the metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(y_true, y_score):\n",
    "    # True positive\n",
    "    tp = np.sum(y_true * y_score)\n",
    "    # False positive\n",
    "    fp = np.sum((y_true == 0) * y_score)\n",
    "    # True negative\n",
    "    tn = np.sum((y_true==0) * (y_score==0))\n",
    "    # False negative\n",
    "    fn = np.sum(y_true * (y_score==0))\n",
    "\n",
    "    # True positive rate (sensitivity or recall)\n",
    "    tpr = tp / (tp + fn)\n",
    "    # False positive rate (fall-out)\n",
    "    fpr = fp / (fp + tn)\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp)\n",
    "    # True negatvie tate (specificity)\n",
    "    tnr = 1 - fpr\n",
    "    # F1 score\n",
    "    f1 = 2*tp / (2*tp + fp + fn)\n",
    "    # ROC-AUC for binary classification\n",
    "    auc = (tpr+tnr) / 2\n",
    "    # MCC\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    print(\"True positive: \", tp)\n",
    "    print(\"False positive: \", fp)\n",
    "    print(\"True negative: \", tn)\n",
    "    print(\"False negative: \", fn)\n",
    "\n",
    "    print(\"True positive rate (recall): \", tpr)\n",
    "    print(\"False positive rate: \", fpr)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"True negative rate (Specificity): \", tnr)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"ROC-AUC: \", auc)\n",
    "    print(\"MCC: \", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: 1\n",
      "[1,   1] loss: 0.014718180\n",
      "Neural Network accuracy for validation set 1: 19.69%\n",
      "Neural Network accuracy on test set: 19.72%\n",
      "[21,   1] loss: 0.004158190\n",
      "Neural Network accuracy for validation set 1: 80.31%\n",
      "Neural Network accuracy on test set: 80.28%\n",
      "[41,   1] loss: 0.003327143\n",
      "Neural Network accuracy for validation set 1: 87.54%\n",
      "Neural Network accuracy on test set: 87.22%\n",
      "[61,   1] loss: 0.002975570\n",
      "Neural Network accuracy for validation set 1: 88.46%\n",
      "Neural Network accuracy on test set: 88.06%\n",
      "[81,   1] loss: 0.002814355\n",
      "Neural Network accuracy for validation set 1: 89.23%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[101,   1] loss: 0.002698296\n",
      "Neural Network accuracy for validation set 1: 89.85%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[121,   1] loss: 0.002608443\n",
      "Neural Network accuracy for validation set 1: 90.77%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[141,   1] loss: 0.002518990\n",
      "Neural Network accuracy for validation set 1: 91.08%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[161,   1] loss: 0.002431592\n",
      "Neural Network accuracy for validation set 1: 91.38%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[181,   1] loss: 0.002342068\n",
      "Neural Network accuracy for validation set 1: 91.23%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[201,   1] loss: 0.002255933\n",
      "Neural Network accuracy for validation set 1: 91.23%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[221,   1] loss: 0.002171650\n",
      "Neural Network accuracy for validation set 1: 91.23%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[241,   1] loss: 0.002093721\n",
      "Neural Network accuracy for validation set 1: 91.23%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[261,   1] loss: 0.002023500\n",
      "Neural Network accuracy for validation set 1: 91.38%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[281,   1] loss: 0.001958169\n",
      "Neural Network accuracy for validation set 1: 91.38%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[301,   1] loss: 0.001888604\n",
      "Neural Network accuracy for validation set 1: 91.08%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[321,   1] loss: 0.001827108\n",
      "Neural Network accuracy for validation set 1: 91.23%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[341,   1] loss: 0.001776234\n",
      "Neural Network accuracy for validation set 1: 91.38%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[361,   1] loss: 0.001713891\n",
      "Neural Network accuracy for validation set 1: 91.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[381,   1] loss: 0.001658273\n",
      "Neural Network accuracy for validation set 1: 91.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "Finished Training\n",
      "Cross Validation: 2\n",
      "[1,   1] loss: 0.001675561\n",
      "Neural Network accuracy for validation set 2: 95.38%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[21,   1] loss: 0.001616562\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[41,   1] loss: 0.001539297\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[61,   1] loss: 0.001479104\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[81,   1] loss: 0.001431508\n",
      "Neural Network accuracy for validation set 2: 95.54%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[101,   1] loss: 0.001389346\n",
      "Neural Network accuracy for validation set 2: 95.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[121,   1] loss: 0.001340719\n",
      "Neural Network accuracy for validation set 2: 95.54%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[141,   1] loss: 0.001311413\n",
      "Neural Network accuracy for validation set 2: 95.08%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[161,   1] loss: 0.001285556\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[181,   1] loss: 0.001236988\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[201,   1] loss: 0.001186417\n",
      "Neural Network accuracy for validation set 2: 95.08%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[221,   1] loss: 0.001150229\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[241,   1] loss: 0.001100632\n",
      "Neural Network accuracy for validation set 2: 95.23%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[261,   1] loss: 0.001055420\n",
      "Neural Network accuracy for validation set 2: 95.08%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[281,   1] loss: 0.001003304\n",
      "Neural Network accuracy for validation set 2: 95.08%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[301,   1] loss: 0.000960626\n",
      "Neural Network accuracy for validation set 2: 94.62%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[321,   1] loss: 0.000921910\n",
      "Neural Network accuracy for validation set 2: 94.62%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[341,   1] loss: 0.000862424\n",
      "Neural Network accuracy for validation set 2: 94.62%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[361,   1] loss: 0.000825742\n",
      "Neural Network accuracy for validation set 2: 94.62%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[381,   1] loss: 0.000770315\n",
      "Neural Network accuracy for validation set 2: 94.31%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "Finished Training\n",
      "Cross Validation: 3\n",
      "[1,   1] loss: 0.000922719\n",
      "Neural Network accuracy for validation set 3: 98.31%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[21,   1] loss: 0.001095880\n",
      "Neural Network accuracy for validation set 3: 98.31%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[41,   1] loss: 0.000983777\n",
      "Neural Network accuracy for validation set 3: 98.31%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[61,   1] loss: 0.000901811\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[81,   1] loss: 0.000830159\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[101,   1] loss: 0.000767823\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[121,   1] loss: 0.000701330\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[141,   1] loss: 0.000635079\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[161,   1] loss: 0.000561130\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[181,   1] loss: 0.000501126\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[201,   1] loss: 0.000437336\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[221,   1] loss: 0.000386208\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[241,   1] loss: 0.000337003\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[261,   1] loss: 0.000305594\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[281,   1] loss: 0.000279137\n",
      "Neural Network accuracy for validation set 3: 98.62%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[301,   1] loss: 0.000248726\n",
      "Neural Network accuracy for validation set 3: 98.77%\n",
      "Neural Network accuracy on test set: 91.94%\n",
      "[321,   1] loss: 0.000223858\n",
      "Neural Network accuracy for validation set 3: 98.46%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[341,   1] loss: 0.000204072\n",
      "Neural Network accuracy for validation set 3: 98.31%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[361,   1] loss: 0.000191037\n",
      "Neural Network accuracy for validation set 3: 98.15%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[381,   1] loss: 0.000176062\n",
      "Neural Network accuracy for validation set 3: 98.15%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "Finished Training\n",
      "Cross Validation: 4\n",
      "[1,   1] loss: 0.000168383\n",
      "Neural Network accuracy for validation set 4: 99.54%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[21,   1] loss: 0.000165534\n",
      "Neural Network accuracy for validation set 4: 99.23%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[41,   1] loss: 0.000135188\n",
      "Neural Network accuracy for validation set 4: 99.23%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[61,   1] loss: 0.000109144\n",
      "Neural Network accuracy for validation set 4: 99.08%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[81,   1] loss: 0.000098148\n",
      "Neural Network accuracy for validation set 4: 98.77%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[101,   1] loss: 0.000086233\n",
      "Neural Network accuracy for validation set 4: 98.77%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[121,   1] loss: 0.000077292\n",
      "Neural Network accuracy for validation set 4: 98.77%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[141,   1] loss: 0.000073353\n",
      "Neural Network accuracy for validation set 4: 98.77%\n",
      "Neural Network accuracy on test set: 91.39%\n",
      "[161,   1] loss: 0.000069871\n",
      "Neural Network accuracy for validation set 4: 98.77%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[181,   1] loss: 0.000068327\n",
      "Neural Network accuracy for validation set 4: 98.61%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[201,   1] loss: 0.000064291\n",
      "Neural Network accuracy for validation set 4: 98.61%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[221,   1] loss: 0.000062593\n",
      "Neural Network accuracy for validation set 4: 98.61%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[241,   1] loss: 0.000060085\n",
      "Neural Network accuracy for validation set 4: 98.46%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[261,   1] loss: 0.000059204\n",
      "Neural Network accuracy for validation set 4: 98.46%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[281,   1] loss: 0.000056882\n",
      "Neural Network accuracy for validation set 4: 98.46%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[301,   1] loss: 0.000055941\n",
      "Neural Network accuracy for validation set 4: 98.46%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[321,   1] loss: 0.000054629\n",
      "Neural Network accuracy for validation set 4: 98.31%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[341,   1] loss: 0.000054992\n",
      "Neural Network accuracy for validation set 4: 98.31%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[361,   1] loss: 0.000053550\n",
      "Neural Network accuracy for validation set 4: 98.31%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[381,   1] loss: 0.000051740\n",
      "Neural Network accuracy for validation set 4: 98.31%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "Finished Training\n",
      "Cross Validation: 5\n",
      "[1,   1] loss: 0.000052763\n",
      "Neural Network accuracy for validation set 5: 99.85%\n",
      "Neural Network accuracy on test set: 91.67%\n",
      "[21,   1] loss: 0.000086914\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[41,   1] loss: 0.000078893\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.28%\n",
      "[61,   1] loss: 0.000074517\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.28%\n",
      "[81,   1] loss: 0.000068183\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.28%\n",
      "[101,   1] loss: 0.000065975\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.28%\n",
      "[121,   1] loss: 0.000063940\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[141,   1] loss: 0.000062804\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[161,   1] loss: 0.000061603\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[181,   1] loss: 0.000060485\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[201,   1] loss: 0.000058288\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.56%\n",
      "[221,   1] loss: 0.000057237\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 90.83%\n",
      "[241,   1] loss: 0.000057185\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[261,   1] loss: 0.000055534\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[281,   1] loss: 0.000055167\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[301,   1] loss: 0.000053581\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[321,   1] loss: 0.000052449\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[341,   1] loss: 0.000051709\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[361,   1] loss: 0.000051517\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "[381,   1] loss: 0.000050509\n",
      "Neural Network accuracy for validation set 5: 99.69%\n",
      "Neural Network accuracy on test set: 91.11%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# For Trainning and validation set DeepTropism_1\n",
    "# Define the cross validation indices for trainning and validation sets\n",
    "crossval_val_indices = np.array_split(train_val_indices,5)\n",
    "\n",
    "# Iterate over crossval_val_indices defining the Dataloaders\n",
    "for n in range(len(crossval_val_indices)):\n",
    "    print(f'Cross Validation: {n + 1}')\n",
    "    trainning_data = []\n",
    "    trainning_label = []\n",
    "    validation_data = []\n",
    "    validation_label = []\n",
    "\n",
    "    validation_indices = list(crossval_val_indices[n])\n",
    "    trainning_indices = list(set(train_val_indices) - set(validation_indices))\n",
    "\n",
    "    for j in validation_indices:\n",
    "        validation_data.append(list_data[j])\n",
    "        validation_label.append(np.array(list_labels[j]))\n",
    "\n",
    "    validation_tensor_x = torch.stack([torch.from_numpy(i) for i in validation_data]) # transform to torch tensors\n",
    "    validation_tensor_y = torch.stack([torch.from_numpy(i) for i in validation_label])\n",
    "\n",
    "    validation_dataset = torch.utils.data.TensorDataset(validation_tensor_x,validation_tensor_y) # create your test dataset\n",
    "    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=64) # create your dataloader\n",
    "    \n",
    "    for k in trainning_indices:\n",
    "        trainning_data.append(list_data[k])\n",
    "        trainning_label.append(np.array(list_labels[k]))\n",
    "\n",
    "    trainning_tensor_x = torch.stack([torch.from_numpy(i) for i in trainning_data]) # transform to torch tensors\n",
    "    trainning_tensor_y = torch.stack([torch.from_numpy(i) for i in trainning_label])\n",
    "\n",
    "    trainning_dataset = torch.utils.data.TensorDataset(trainning_tensor_x,trainning_tensor_y) # create your test dataset\n",
    "    trainning_dataloader = torch.utils.data.DataLoader(trainning_dataset, batch_size=64) # create your dataloader\n",
    "    \n",
    "    # Instantiante new model\n",
    "    #model = DeepTropism_1().float()\n",
    "        \n",
    "    # Define Cross Validation Trainning Loop\n",
    "    for epoch in range(400):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainning_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            #print(running_loss)\n",
    "            #if i % 3239 == 0:    # print every 3239 mini-batches\n",
    "            if epoch % 20 == 0 and i % 3248 == 0:\n",
    "                print('[%d, %3d] loss: %.9f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 50))\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                error = 0\n",
    "                labels_array = np.empty([0])\n",
    "                predict_array = np.empty([0])\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for data in validation_dataloader:\n",
    "                        images, labels = data\n",
    "                        outputs = model(images.float())\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                        labels_array = np.concatenate([labels_array, labels])\n",
    "                        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                        error += (predicted != labels).sum().item()\n",
    "\n",
    "                print(f'Neural Network accuracy for validation set {n + 1}: {round(100.0 * correct/total, 2)}%')\n",
    "                \n",
    "                # Evaluate model against test set\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                error = 0\n",
    "                labels_array = np.empty([0])\n",
    "                predict_array = np.empty([0])\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for data in test_dataloader:\n",
    "                        images, labels = data\n",
    "                        outputs = model(images.float())\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                        labels_array = np.concatenate([labels_array, labels])\n",
    "                        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                        error += (predicted != labels).sum().item()\n",
    "\n",
    "                print(f'Neural Network accuracy on test set: {round(100.0 * correct/total, 2)}%')\n",
    "\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            \n",
    "            \n",
    "    torch.save(model.state_dict(), f'model_cv{n+1}.ptb')\n",
    "    print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy for test set: 91.39%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy for test set: {round(100.0 * correct/total, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive:  53.0\n",
      "False positive:  13.0\n",
      "True negative:  276\n",
      "False negative:  18.0\n",
      "True positive rate (recall):  0.7464788732394366\n",
      "False positive rate:  0.04498269896193772\n",
      "Precision:  0.803030303030303\n",
      "True negative rate (Specificity):  0.9550173010380623\n",
      "F1:  0.7737226277372263\n",
      "ROC-AUC:  0.8507480871387494\n",
      "MCC:  0.7213694892638097\n"
     ]
    }
   ],
   "source": [
    "show_metrics(labels_array, predict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of DNN model against published datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newdb\n",
    "df_cm\n",
    "df_hivcopred\n",
    "df_geno2pheno\n",
    "df_webpssm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Newdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data_newdb = []\n",
    "list_labels_newdb = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df_newdb.iterrows():\n",
    "    list_data_newdb.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels_newdb.append(np.array(int(row.label_numeric)))\n",
    "\n",
    "newdb_tensor_x = torch.stack([torch.from_numpy(i) for i in list_data_newdb]) # transform to torch tensors\n",
    "newdb_tensor_y = torch.stack([torch.from_numpy(i) for i in list_labels_newdb])\n",
    "\n",
    "newdb_dataset = torch.utils.data.TensorDataset(newdb_tensor_x,newdb_tensor_y) # create your test dataset\n",
    "newdb_dataloader = torch.utils.data.DataLoader(newdb_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy on test set: 99.03%\n",
      "True positive:  646.0\n",
      "False positive:  12.0\n",
      "True negative:  2323\n",
      "False negative:  17.0\n",
      "True positive rate (recall):  0.9743589743589743\n",
      "False positive rate:  0.005139186295503212\n",
      "Precision:  0.9817629179331308\n",
      "True negative rate (Specificity):  0.9948608137044967\n",
      "F1:  0.9780469341408025\n",
      "ROC-AUC:  0.9846098940317356\n",
      "MCC:  0.9718552911349981\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in newdb_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy on test set: {round(100.0 * correct/total, 2)}%')\n",
    "show_metrics(labels_array, predict_array)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For CM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data_cm = []\n",
    "list_labels_cm = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df_cm.iterrows():\n",
    "    list_data_cm.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels_cm.append(np.array(int(row.label_numeric)))\n",
    "\n",
    "cm_tensor_x = torch.stack([torch.from_numpy(i) for i in list_data_cm]) # transform to torch tensors\n",
    "cm_tensor_y = torch.stack([torch.from_numpy(i) for i in list_labels_cm])\n",
    "\n",
    "cm_dataset = torch.utils.data.TensorDataset(cm_tensor_x,cm_tensor_y) # create your test dataset\n",
    "cm_dataloader = torch.utils.data.DataLoader(cm_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy on test set: 98.02%\n",
      "True positive:  319.0\n",
      "False positive:  47.0\n",
      "True negative:  2307\n",
      "False negative:  6.0\n",
      "True positive rate (recall):  0.9815384615384616\n",
      "False positive rate:  0.019966015293118096\n",
      "Precision:  0.8715846994535519\n",
      "True negative rate (Specificity):  0.9800339847068819\n",
      "F1:  0.9232995658465991\n",
      "ROC-AUC:  0.9807862231226717\n",
      "MCC:  0.9141102122892164\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in cm_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy on test set: {round(100.0 * correct/total, 2)}%')\n",
    "show_metrics(labels_array, predict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For hivcopred dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data_hivcopred = []\n",
    "list_labels_hivcopred = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df_hivcopred.iterrows():\n",
    "    list_data_hivcopred.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels_hivcopred.append(np.array(int(row.label_numeric)))\n",
    "\n",
    "hivcopred_tensor_x = torch.stack([torch.from_numpy(i) for i in list_data_hivcopred]) # transform to torch tensors\n",
    "hivcopred_tensor_y = torch.stack([torch.from_numpy(i) for i in list_labels_hivcopred])\n",
    "\n",
    "hivcopred_dataset = torch.utils.data.TensorDataset(hivcopred_tensor_x,hivcopred_tensor_y) # create your test dataset\n",
    "hivcopred_dataloader = torch.utils.data.DataLoader(hivcopred_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy on hivcopred set: 97.86%\n",
      "True positive:  529.0\n",
      "False positive:  12.0\n",
      "True negative:  1756\n",
      "False negative:  38.0\n",
      "True positive rate (recall):  0.9329805996472663\n",
      "False positive rate:  0.006787330316742082\n",
      "Precision:  0.977818853974122\n",
      "True negative rate (Specificity):  0.9932126696832579\n",
      "F1:  0.9548736462093863\n",
      "ROC-AUC:  0.9630966346652621\n",
      "MCC:  0.9412921319180905\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in hivcopred_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy on hivcopred set: {round(100.0 * correct/total, 2)}%')\n",
    "show_metrics(labels_array, predict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For geno2pheno dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data_geno2pheno = []\n",
    "list_labels_geno2pheno = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df_geno2pheno.iterrows():\n",
    "    list_data_geno2pheno.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels_geno2pheno.append(np.array(int(row.label_numeric)))\n",
    "\n",
    "geno2pheno_tensor_x = torch.stack([torch.from_numpy(i) for i in list_data_geno2pheno]) # transform to torch tensors\n",
    "geno2pheno_tensor_y = torch.stack([torch.from_numpy(i) for i in list_labels_geno2pheno])\n",
    "\n",
    "geno2pheno_dataset = torch.utils.data.TensorDataset(geno2pheno_tensor_x,geno2pheno_tensor_y) # create your test dataset\n",
    "geno2pheno_dataloader = torch.utils.data.DataLoader(geno2pheno_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy on hivcopred set: 95.96%\n",
      "True positive:  191.0\n",
      "False positive:  24.0\n",
      "True negative:  949\n",
      "False negative:  24.0\n",
      "True positive rate (recall):  0.8883720930232558\n",
      "False positive rate:  0.024665981500513873\n",
      "Precision:  0.8883720930232558\n",
      "True negative rate (Specificity):  0.9753340184994861\n",
      "F1:  0.8883720930232558\n",
      "ROC-AUC:  0.9318530557613709\n",
      "MCC:  0.8637061115227419\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in geno2pheno_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy on hivcopred set: {round(100.0 * correct/total, 2)}%')\n",
    "show_metrics(labels_array, predict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For webpssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data_webpssm = []\n",
    "list_labels_webpssm = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df_webpssm.iterrows():\n",
    "    list_data_webpssm.append(get_array_from_sequence(str(row.sequence_aligned)))\n",
    "    list_labels_webpssm.append(np.array(int(row.label_numeric)))\n",
    "\n",
    "webpssm_tensor_x = torch.stack([torch.from_numpy(i) for i in list_data_webpssm]) # transform to torch tensors\n",
    "webpssm_tensor_y = torch.stack([torch.from_numpy(i) for i in list_labels_webpssm])\n",
    "\n",
    "webpssm_dataset = torch.utils.data.TensorDataset(webpssm_tensor_x,webpssm_tensor_y) # create your test dataset\n",
    "webpssm_dataloader = torch.utils.data.DataLoader(webpssm_dataset, batch_size=64) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy on webpssm set: 96.29%\n",
      "True positive:  69.0\n",
      "False positive:  7.0\n",
      "True negative:  268\n",
      "False negative:  6.0\n",
      "True positive rate (recall):  0.92\n",
      "False positive rate:  0.025454545454545455\n",
      "Precision:  0.9078947368421053\n",
      "True negative rate (Specificity):  0.9745454545454545\n",
      "F1:  0.9139072847682119\n",
      "ROC-AUC:  0.9472727272727273\n",
      "MCC:  0.8902609299817448\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "error = 0\n",
    "labels_array = np.empty([0])\n",
    "predict_array = np.empty([0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in webpssm_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        labels_array = np.concatenate([labels_array, labels])\n",
    "        predict_array = np.concatenate([predict_array, predicted])\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        error += (predicted != labels).sum().item()\n",
    "\n",
    "print(f'Neural Network accuracy on webpssm set: {round(100.0 * correct/total, 2)}%')\n",
    "show_metrics(labels_array, predict_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptropism",
   "language": "python",
   "name": "deeptropism"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
