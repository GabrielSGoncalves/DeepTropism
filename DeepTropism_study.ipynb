{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('artifacts/newdb_aligned.csv', sep='\\t', names=['name', 'sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1432|KF859742|O|CCR5</td>\n",
       "      <td>C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MD47|KF859744|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BCF02|U24562|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>152|KF859743|O|CCR5</td>\n",
       "      <td>C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DUR|X84327|O|CCR5</td>\n",
       "      <td>C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                           sequence\n",
       "0  1432|KF859742|O|CCR5  C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...\n",
       "1  MD47|KF859744|O|CCR5  C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...\n",
       "2   BCF02|U24562|O|CCR5  C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...\n",
       "3   152|KF859743|O|CCR5  C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...\n",
       "4     DUR|X84327|O|CCR5  C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ccr5</th>\n",
       "      <th>cxcr4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1432|KF859742|O|CCR5</td>\n",
       "      <td>C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MD47|KF859744|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BCF02|U24562|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>152|KF859743|O|CCR5</td>\n",
       "      <td>C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DUR|X84327|O|CCR5</td>\n",
       "      <td>C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DUR|AM262121|O|CCR5</td>\n",
       "      <td>C-VRPGNN-SV-QE---M-R--VGP--M--A-WY--SM-----ELE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DUR|AM262130|O|CCR5</td>\n",
       "      <td>C-VRPGNN-SV-KE---M-R--VGP--M--A-LY--SM-----ELE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DUR|AM262127|O|CCR5</td>\n",
       "      <td>C-VRPGDN-SV-KE---M-R--AGP-----MAWY--SM-----ELE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CA9|X96522|O|CCR5</td>\n",
       "      <td>C-ERPGNH-TV-QE---I-R--IGP-LA----WY--SM---G-IEK...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>BCF01|U24566|O|CCR5</td>\n",
       "      <td>C-HRPGNL-SV-QE---M-K--IGP--LS---WY--SM---G-LAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                           sequence  \\\n",
       "0  1432|KF859742|O|CCR5  C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...   \n",
       "1  MD47|KF859744|O|CCR5  C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...   \n",
       "2   BCF02|U24562|O|CCR5  C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...   \n",
       "3   152|KF859743|O|CCR5  C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...   \n",
       "4     DUR|X84327|O|CCR5  C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE...   \n",
       "5   DUR|AM262121|O|CCR5  C-VRPGNN-SV-QE---M-R--VGP--M--A-WY--SM-----ELE...   \n",
       "6   DUR|AM262130|O|CCR5  C-VRPGNN-SV-KE---M-R--VGP--M--A-LY--SM-----ELE...   \n",
       "7   DUR|AM262127|O|CCR5  C-VRPGDN-SV-KE---M-R--AGP-----MAWY--SM-----ELE...   \n",
       "8     CA9|X96522|O|CCR5  C-ERPGNH-TV-QE---I-R--IGP-LA----WY--SM---G-IEK...   \n",
       "9   BCF01|U24566|O|CCR5  C-HRPGNL-SV-QE---M-K--IGP--LS---WY--SM---G-LAA...   \n",
       "\n",
       "   ccr5  cxcr4  \n",
       "0  True  False  \n",
       "1  True  False  \n",
       "2  True  False  \n",
       "3  True  False  \n",
       "4  True  False  \n",
       "5  True  False  \n",
       "6  True  False  \n",
       "7  True  False  \n",
       "8  True  False  \n",
       "9  True  False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Labels\n",
    "# For CCR5\n",
    "df['ccr5'] = df.name.str.contains('CCR5')\n",
    "df['cxcr4'] = df.name.str.contains('CXCR4')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = df.loc[0, 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call labels\n",
    "def tropism_label(row):\n",
    "    \n",
    "    if row.ccr5 and row.cxcr4:\n",
    "        #return 'dual_tropic'\n",
    "        return '0'\n",
    "    elif row.ccr5:\n",
    "        #return 'CCR5'\n",
    "        return 1\n",
    "    elif row.cxcr4:\n",
    "        #return 'CXCR4'\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.apply(tropism_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2354\n",
       "2     277\n",
       "0      48\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2631"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.ccr5 == False)|(df.cxcr4 == False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2679, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ccr5</th>\n",
       "      <th>cxcr4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1432|KF859742|O|CCR5</td>\n",
       "      <td>C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MD47|KF859744|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BCF02|U24562|O|CCR5</td>\n",
       "      <td>C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>152|KF859743|O|CCR5</td>\n",
       "      <td>C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DUR|X84327|O|CCR5</td>\n",
       "      <td>C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2674</td>\n",
       "      <td>H13988_DS2|JF508074|B|CCR5</td>\n",
       "      <td>C-TRPNNN-TR-KS---I-H--IGP-GK--A-FY--TT---G-EII...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>H13988_DS2|JF508043|B|CCR5</td>\n",
       "      <td>C-TRPNNN-TR-KS---I-P--IGP-GK--A-FY--TT---G-EII...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2676</td>\n",
       "      <td>39|AF022258|B|CCR5</td>\n",
       "      <td>C-TRPNNN-TR-KS---I-S--IGP-GR--A-FY--TT---G-EII...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2677</td>\n",
       "      <td>122|DQ002264|B|CCR5</td>\n",
       "      <td>C-TRPNNN-TR-KS---I-P--IGP-GR--A-FY--TT---G-EII...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2678</td>\n",
       "      <td>Pat1|AF541016|B|CCR5</td>\n",
       "      <td>C-TRPNNN-TR-KS---I-P--IGP-GR--A-FY--TT---G-EII...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2679 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0           1432|KF859742|O|CCR5   \n",
       "1           MD47|KF859744|O|CCR5   \n",
       "2            BCF02|U24562|O|CCR5   \n",
       "3            152|KF859743|O|CCR5   \n",
       "4              DUR|X84327|O|CCR5   \n",
       "...                          ...   \n",
       "2674  H13988_DS2|JF508074|B|CCR5   \n",
       "2675  H13988_DS2|JF508043|B|CCR5   \n",
       "2676          39|AF022258|B|CCR5   \n",
       "2677         122|DQ002264|B|CCR5   \n",
       "2678        Pat1|AF541016|B|CCR5   \n",
       "\n",
       "                                               sequence  ccr5  cxcr4 label  \n",
       "0     C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK...  True  False     1  \n",
       "1     C-QRPGHQ-EI-QE---I-K--TGP-----LAWY--SMYLKE-NTT...  True  False     1  \n",
       "2     C-QRPGHQ-TV-QE---I-R--IGP-----MAWY--SM---G-LAA...  True  False     1  \n",
       "3     C-RRPAMK--V-QE---M-R--IGP----MA-WY--SMALEE-GNN...  True  False     1  \n",
       "4     C-VRPGNN-SV-QE---I-K--IGP-----MAWY--SM-----QIE...  True  False     1  \n",
       "...                                                 ...   ...    ...   ...  \n",
       "2674  C-TRPNNN-TR-KS---I-H--IGP-GK--A-FY--TT---G-EII...  True  False     1  \n",
       "2675  C-TRPNNN-TR-KS---I-P--IGP-GK--A-FY--TT---G-EII...  True  False     1  \n",
       "2676  C-TRPNNN-TR-KS---I-S--IGP-GR--A-FY--TT---G-EII...  True  False     1  \n",
       "2677  C-TRPNNN-TR-KS---I-P--IGP-GR--A-FY--TT---G-EII...  True  False     1  \n",
       "2678  C-TRPNNN-TR-KS---I-P--IGP-GR--A-FY--TT---G-EII...  True  False     1  \n",
       "\n",
       "[2679 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{60}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check of len of sequence is the same for all rows\n",
    "set(df['sequence'].apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Protein Sequence to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aa = pd.read_csv('artifacts/aminoacids_oneletter_code.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos_array</th>\n",
       "      <th>3-letters-code</th>\n",
       "      <th>1-letter-code</th>\n",
       "      <th>Aminoacid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ala</td>\n",
       "      <td>A</td>\n",
       "      <td>Alanine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asn</td>\n",
       "      <td>N</td>\n",
       "      <td>Asparagine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Asp</td>\n",
       "      <td>D</td>\n",
       "      <td>Aspartic acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cys</td>\n",
       "      <td>C</td>\n",
       "      <td>Cysteine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gln</td>\n",
       "      <td>Q</td>\n",
       "      <td>Glutamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Glu</td>\n",
       "      <td>E</td>\n",
       "      <td>Glutamic acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Gly</td>\n",
       "      <td>G</td>\n",
       "      <td>Glycine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>His</td>\n",
       "      <td>H</td>\n",
       "      <td>Histidine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Ile</td>\n",
       "      <td>I</td>\n",
       "      <td>Isoleucine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Leu</td>\n",
       "      <td>L</td>\n",
       "      <td>Leucine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Lys</td>\n",
       "      <td>K</td>\n",
       "      <td>Lysine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Met</td>\n",
       "      <td>M</td>\n",
       "      <td>Methionine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Phe</td>\n",
       "      <td>F</td>\n",
       "      <td>Phenylalanine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Pro</td>\n",
       "      <td>P</td>\n",
       "      <td>Proline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Pyl</td>\n",
       "      <td>O</td>\n",
       "      <td>Pyrrolysine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Ser</td>\n",
       "      <td>S</td>\n",
       "      <td>Serine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Sec</td>\n",
       "      <td>U</td>\n",
       "      <td>Selenocysteine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Thr</td>\n",
       "      <td>T</td>\n",
       "      <td>Threonine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Trp</td>\n",
       "      <td>W</td>\n",
       "      <td>Tryptophan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Tyr</td>\n",
       "      <td>Y</td>\n",
       "      <td>Tyrosine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Val</td>\n",
       "      <td>V</td>\n",
       "      <td>Valine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asx</td>\n",
       "      <td>B</td>\n",
       "      <td>Aspartic acid or Asparagine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Glx</td>\n",
       "      <td>Z</td>\n",
       "      <td>Glutamic acid or Glutamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Xaa</td>\n",
       "      <td>X</td>\n",
       "      <td>Any amino acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Xle</td>\n",
       "      <td>J</td>\n",
       "      <td>Leucine or Isoleucine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ept</td>\n",
       "      <td>-</td>\n",
       "      <td>Empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pos_array 3-letters-code 1-letter-code                    Aminoacid\n",
       "0         1.0            Ala             A                      Alanine\n",
       "1         2.0            Asn             N                   Asparagine\n",
       "2         3.0            Asp             D                Aspartic acid\n",
       "3         4.0            Cys             C                     Cysteine\n",
       "4         5.0            Gln             Q                    Glutamine\n",
       "5         6.0            Glu             E                Glutamic acid\n",
       "6         7.0            Gly             G                      Glycine\n",
       "7         8.0            His             H                    Histidine\n",
       "8         9.0            Ile             I                   Isoleucine\n",
       "9        10.0            Leu             L                      Leucine\n",
       "10       11.0            Lys             K                       Lysine\n",
       "11       12.0            Met             M                   Methionine\n",
       "12       13.0            Phe             F                Phenylalanine\n",
       "13       14.0            Pro             P                      Proline\n",
       "14       15.0            Pyl             O                  Pyrrolysine\n",
       "15       16.0            Ser             S                       Serine\n",
       "16       17.0            Sec             U               Selenocysteine\n",
       "17       18.0            Thr             T                    Threonine\n",
       "18       19.0            Trp             W                   Tryptophan\n",
       "19       20.0            Tyr             Y                     Tyrosine\n",
       "20       21.0            Val             V                       Valine\n",
       "21       22.0            Asx             B  Aspartic acid or Asparagine\n",
       "22       23.0            Glx             Z   Glutamic acid or Glutamine\n",
       "23       24.0            Xaa             X               Any amino acid\n",
       "24       25.0            Xle             J        Leucine or Isoleucine\n",
       "25        NaN            Ept             -                        Empty"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'N',\n",
       " 'D',\n",
       " 'C',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'L',\n",
       " 'K',\n",
       " 'M',\n",
       " 'F',\n",
       " 'P',\n",
       " 'O',\n",
       " 'S',\n",
       " 'U',\n",
       " 'T',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'V',\n",
       " 'B',\n",
       " 'Z',\n",
       " 'X',\n",
       " 'J',\n",
       " '-']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aa['1-letter-code'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_from_sequence(seq):\n",
    "    dict_aa_pos = {\n",
    "    'A':1, 'R':2, 'N':3, 'D':4, 'C':5, 'Q':6, 'E':7, 'G':8,\n",
    "    'H':9, 'I':10, 'L':11, 'K':12, 'M':13, 'F':14, 'P':15, \n",
    "    'O':16, 'S':17, 'U':18, 'T':19, 'W':20, 'Y':21, 'V':22, \n",
    "    'B':23, 'Z':24, 'J':25, 'X':0, }\n",
    "    \n",
    "    f_array = np.zeros(26)\n",
    "    for aa in seq:\n",
    "        arr = np.zeros(26)\n",
    "        if dict_aa_pos.get(aa):\n",
    "            arr[dict_aa_pos.get(aa)] = 1\n",
    "        f_array = np.vstack((f_array, arr))\n",
    "    f_array = np.delete(f_array, 0,0)\n",
    "    \n",
    "    return torch.from_numpy((f_array.flatten()).astype(float))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = get_array_from_sequence('C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK--G--N-RTRLAYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37., dtype=torch.float64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C-ERPTMD--I-QD---I-H--IGP----MA-WY--STYIER-QAK--G--N-RTRLAYC'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append data from the df\n",
    "list_data = []\n",
    "list_labels = []\n",
    "\n",
    "# Convert the sequences and labels to arrays to use as data on pytorch\n",
    "for index, row in df.iterrows():\n",
    "    list_data.append(get_array_from_sequence(str(row.sequence)))\n",
    "    list_labels.append(int(row.label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1560])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(list_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# To transform list_data and list_labels on trainloader\n",
    "\n",
    "# For training\n",
    "train_data = []\n",
    "for i in train_indices:\n",
    "    train_data.append([list_data[i], list_labels[i]])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=32)\n",
    "\n",
    "# For validation\n",
    "test_data = []\n",
    "for j in val_indices:\n",
    "    test_data.append([list_data[j], list_labels[j]])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the class Net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "        # Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1560, 200)\n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        # Do the forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = Net()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # input channel = 1, output channel = 6, kernel_size = 5\n",
    "        # input size = (32, 32), output size = (28, 28)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # input channel = 6, output channel = 16, kernel_size = 5\n",
    "        # input size = (14, 14), output size = (10, 10)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # input dim = 16*5*5, output dim = 120\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # input dim = 120, output dim = 84\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # input dim = 84, output dim = 10\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pool size = 2\n",
    "        # input size = (28, 28), output size = (14, 14), output channel = 6\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # pool size = 2\n",
    "        # input size = (10, 10), output size = (5, 5), output channel = 16\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # input dim = 16*5*5, output dim = 120\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # input dim = 120, output dim = 84\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # input dim = 84, output dim = 10\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(1560, 830)\n",
    "        self.fc2 = nn.Linear(830, 100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.001\n",
      "[2,     1] loss: 0.000\n",
      "[3,     1] loss: 0.000\n",
      "[4,     1] loss: 0.000\n",
      "[5,     1] loss: 0.001\n",
      "[6,     1] loss: 0.001\n",
      "[7,     1] loss: 0.000\n",
      "[8,     1] loss: 0.000\n",
      "[9,     1] loss: 0.002\n",
      "[10,     1] loss: 0.001\n",
      "[11,     1] loss: 0.000\n",
      "[12,     1] loss: 0.000\n",
      "[13,     1] loss: 0.000\n",
      "[14,     1] loss: 0.000\n",
      "[15,     1] loss: 0.001\n",
      "[16,     1] loss: 0.000\n",
      "[17,     1] loss: 0.000\n",
      "[18,     1] loss: 0.000\n",
      "[19,     1] loss: 0.001\n",
      "[20,     1] loss: 0.000\n",
      "[21,     1] loss: 0.001\n",
      "[22,     1] loss: 0.001\n",
      "[23,     1] loss: 0.000\n",
      "[24,     1] loss: 0.000\n",
      "[25,     1] loss: 0.000\n",
      "[26,     1] loss: 0.000\n",
      "[27,     1] loss: 0.000\n",
      "[28,     1] loss: 0.000\n",
      "[29,     1] loss: 0.001\n",
      "[30,     1] loss: 0.000\n",
      "[31,     1] loss: 0.000\n",
      "[32,     1] loss: 0.001\n",
      "[33,     1] loss: 0.000\n",
      "[34,     1] loss: 0.000\n",
      "[35,     1] loss: 0.002\n",
      "[36,     1] loss: 0.000\n",
      "[37,     1] loss: 0.001\n",
      "[38,     1] loss: 0.001\n",
      "[39,     1] loss: 0.000\n",
      "[40,     1] loss: 0.000\n",
      "[41,     1] loss: 0.000\n",
      "[42,     1] loss: 0.000\n",
      "[43,     1] loss: 0.000\n",
      "[44,     1] loss: 0.000\n",
      "[45,     1] loss: 0.000\n",
      "[46,     1] loss: 0.000\n",
      "[47,     1] loss: 0.000\n",
      "[48,     1] loss: 0.000\n",
      "[49,     1] loss: 0.000\n",
      "[50,     1] loss: 0.000\n",
      "[51,     1] loss: 0.000\n",
      "[52,     1] loss: 0.001\n",
      "[53,     1] loss: 0.001\n",
      "[54,     1] loss: 0.000\n",
      "[55,     1] loss: 0.001\n",
      "[56,     1] loss: 0.000\n",
      "[57,     1] loss: 0.000\n",
      "[58,     1] loss: 0.001\n",
      "[59,     1] loss: 0.000\n",
      "[60,     1] loss: 0.000\n",
      "[61,     1] loss: 0.000\n",
      "[62,     1] loss: 0.000\n",
      "[63,     1] loss: 0.001\n",
      "[64,     1] loss: 0.001\n",
      "[65,     1] loss: 0.000\n",
      "[66,     1] loss: 0.000\n",
      "[67,     1] loss: 0.001\n",
      "[68,     1] loss: 0.000\n",
      "[69,     1] loss: 0.000\n",
      "[70,     1] loss: 0.000\n",
      "[71,     1] loss: 0.000\n",
      "[72,     1] loss: 0.000\n",
      "[73,     1] loss: 0.000\n",
      "[74,     1] loss: 0.002\n",
      "[75,     1] loss: 0.000\n",
      "[76,     1] loss: 0.000\n",
      "[77,     1] loss: 0.000\n",
      "[78,     1] loss: 0.000\n",
      "[79,     1] loss: 0.000\n",
      "[80,     1] loss: 0.000\n",
      "[81,     1] loss: 0.001\n",
      "[82,     1] loss: 0.000\n",
      "[83,     1] loss: 0.001\n",
      "[84,     1] loss: 0.000\n",
      "[85,     1] loss: 0.000\n",
      "[86,     1] loss: 0.000\n",
      "[87,     1] loss: 0.001\n",
      "[88,     1] loss: 0.000\n",
      "[89,     1] loss: 0.001\n",
      "[90,     1] loss: 0.000\n",
      "[91,     1] loss: 0.002\n",
      "[92,     1] loss: 0.000\n",
      "[93,     1] loss: 0.000\n",
      "[94,     1] loss: 0.000\n",
      "[95,     1] loss: 0.000\n",
      "[96,     1] loss: 0.000\n",
      "[97,     1] loss: 0.001\n",
      "[98,     1] loss: 0.000\n",
      "[99,     1] loss: 0.000\n",
      "[100,     1] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #print(running_loss)\n",
    "        if i % 1000 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-92-2386f557722c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-92-2386f557722c>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    running_loss = 0.0\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "        #running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Train a classifier Tutorial\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170237952/170498071 [00:42<00:00, 5247626.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse  ship  frog  frog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [01:00, 5247626.11it/s]                               "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.234\n",
      "[1,  4000] loss: 1.898\n",
      "[1,  6000] loss: 1.698\n",
      "[1,  8000] loss: 1.583\n",
      "[1, 10000] loss: 1.512\n",
      "[1, 12000] loss: 1.463\n",
      "[2,  2000] loss: 1.409\n",
      "[2,  4000] loss: 1.369\n",
      "[2,  6000] loss: 1.353\n",
      "[2,  8000] loss: 1.319\n",
      "[2, 10000] loss: 1.311\n",
      "[2, 12000] loss: 1.252\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCamp Deep Learning with Pytorch tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class Net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "        # Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1560, 200)\n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        # Do the forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
    "\n",
    "model = Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c84bae1b73d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Complete a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Compute the loss, gradients and change the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeptropism/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-decf41e26c0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Do the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeptropism/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeptropism/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeptropism/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "for batch_idx, data_target in enumerate(train_loader):\n",
    "    data = data_target[0]\n",
    "    target = data_target[1]\n",
    "    data = data.view(-1, 1560)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Complete a forward pass\n",
    "    output = model(data)\n",
    "\n",
    "    # Compute the loss, gradients and change the weights\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Will Koersten approach for Pytorch\n",
    "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torch.utils.data.sampler import SubsetRandomSampler\\n# Creating PT data samplers and loaders:\\ntrain_sampler = SubsetRandomSampler(train_indices)\\nvalid_sampler = SubsetRandomSampler(val_indices)\\n\\ntrain_loader = torch.utils.data.DataLoader(list_data, batch_size=batch_size, \\n                                           sampler=train_sampler)\\nvalidation_loader = torch.utils.data.DataLoader(list_data, batch_size=batch_size,\\n                                                sampler=valid_sampler)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining dataloader\n",
    "\"\"\"\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(list_data, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(list_data, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network\n",
    "https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-127b02abb45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y = np.array(list_labels).astype(float)\n",
    "X = np.array(list_data).astype(float)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4d16a0ea6f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtorch_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# data type is long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=1560, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(1560,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,3)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 50\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), \n",
    "                    len(train_loader.dataset), \n",
    "                    100.*batch_idx / len(train_loader), \n",
    "                    loss.item(), \n",
    "                    float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Variable data has to be a tensor, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e5142deeb225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-aad2c4e23ae8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvar_X_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mvar_y_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_X_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Variable data has to be a tensor, but got tuple"
     ]
    }
   ],
   "source": [
    "fit(mlp, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will Koehrsen Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying this approach https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1560, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 1560\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 3\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.view(images.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1560])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-7f340e35e909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#log probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the NLL loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "logps = model(images) #log probabilities\n",
    "loss = criterion(logps, labels) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f966643d5d0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 200\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 10 1, but got 2-dimensional input of size [100, 1560] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-26b4aad1314a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-21c42bd276cf>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-f47fd26d5546>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 10 1, but got 2-dimensional input of size [100, 1560] instead"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Pytorch Dataloader\n",
    "### Check this article https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "\n",
    "After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gabriel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "\n",
    "train_file = bz2.BZ2File('./amazonreviews/train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('./amazonreviews/test.ft.txt.bz2')\n",
    "\n",
    "train_file = train_file.readlines()\n",
    "test_file = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 800000  # We're training on the first 800,000 reviews in the dataset\n",
    "num_test = 200000  # Using 200,000 reviews from test set\n",
    "\n",
    "train_file = [x.decode('utf-8') for x in train_file[:num_train]]\n",
    "test_file = [x.decode('utf-8') for x in test_file[:num_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels from sentences\n",
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\n",
    "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]\n",
    "\n",
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]\n",
    "\n",
    "# Some simple cleaning of data\n",
    "for i in range(len(train_sentences)):\n",
    "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
    "\n",
    "# Modify URLs to <url>\n",
    "for i in range(len(train_sentences)):\n",
    "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
    "        \n",
    "for i in range(len(test_sentences)):\n",
    "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      "2.5% done\n",
      "5.0% done\n",
      "7.5% done\n",
      "10.0% done\n",
      "12.5% done\n",
      "15.0% done\n",
      "17.5% done\n",
      "20.0% done\n",
      "22.5% done\n",
      "25.0% done\n",
      "27.5% done\n",
      "30.0% done\n",
      "32.5% done\n",
      "35.0% done\n",
      "37.5% done\n",
      "40.0% done\n",
      "42.5% done\n",
      "45.0% done\n",
      "47.5% done\n",
      "50.0% done\n",
      "52.5% done\n",
      "55.0% done\n",
      "57.5% done\n",
      "60.0% done\n",
      "62.5% done\n",
      "65.0% done\n",
      "67.5% done\n",
      "70.0% done\n",
      "72.5% done\n",
      "75.0% done\n",
      "77.5% done\n",
      "80.0% done\n",
      "82.5% done\n",
      "85.0% done\n",
      "87.5% done\n",
      "90.0% done\n",
      "92.5% done\n",
      "95.0% done\n",
      "97.5% done\n",
      "100% done\n"
     ]
    }
   ],
   "source": [
    "words = Counter()  # Dictionary that will map a word to the number of times it appeared in all the training sentences\n",
    "for i, sentence in enumerate(train_sentences):\n",
    "    # The sentences will be stored as a list of words/tokens\n",
    "    train_sentences[i] = []\n",
    "    for word in nltk.word_tokenize(sentence):  # Tokenizing the words\n",
    "        words.update([word.lower()])  # Converting all the words to lowercase\n",
    "        train_sentences[i].append(word)\n",
    "    if i%20000 == 0:\n",
    "        print(str((i*100)/num_train) + \"% done\")\n",
    "print(\"100% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the words that only appear once\n",
    "words = {k:v for k,v in words.items() if v>1}\n",
    "# Sorting the words according to the number of appearances, with the most common word being first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "words = ['_PAD','_UNK'] + words\n",
    "# Dictionaries to store the word to index mappings and vice versa\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(train_sentences):\n",
    "    # Looking up the mapping dictionary and assigning the index to the respective words\n",
    "    train_sentences[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]\n",
    "\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "    # For test sentences, we have to tokenize the sentences as well\n",
    "    test_sentences[i] = [word2idx[word.lower()] if word.lower() in word2idx else 0 for word in nltk.word_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\n",
    "def pad_input(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "seq_len = 200  # The length that the sentences will be padded/shortened to\n",
    "\n",
    "train_sentences = pad_input(train_sentences, seq_len)\n",
    "test_sentences = pad_input(test_sentences, seq_len)\n",
    "\n",
    "# Converting our labels into numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,  66140,     88,     16,      3, 103103,     13,     11,\n",
       "           192,    459,     18,    361,     15,      9,   5736,      3,\n",
       "         91059,     14,     77,    433,     36,     90,      5,     51,\n",
       "          1662,      9,     88,      8,    141,     80,    616,  18520,\n",
       "             2,    211,    126,     15,      5,     27,    539,      3,\n",
       "           211,  18200,   2031,     22,     56,     10,     35,     10,\n",
       "             3,    792,      5,     27,    131,    539,      9,     58,\n",
       "             3,     96,    126,     15,      9,   7389,    261,     49,\n",
       "          4579,  62414,      6,    427,      7,  17664,   1077,     23,\n",
       "          8888,   2708,      6,   3932,  19348,      2,      9,     51,\n",
       "          4799,    204,     80,   2391,      8,    313,     15,  16999],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      3,     96,    948,    131,      8,\n",
       "           272,      2,     13,      5,    122,    155,      7,    188,\n",
       "            10,    258,    765,     17,     11,     12,      3,     96,\n",
       "         66141,    948,    151,      6,      5,   1529,     17,      5,\n",
       "           295,    485,      7,    274,      8,   3047,      7,    268,\n",
       "             2,     11,     14,     28,      0,     12, 121184,  70507,\n",
       "            21,   1932,   1074,      2,      3,    126,     12,   2152,\n",
       "             6,      5,    122,    105,    526,      8,      9,     16,\n",
       "           152,    129,      6,    136,   1287,    404,   5709,      8,\n",
       "        152656,    215,   3943,     25,     11,     12,    249,  14731,\n",
       "             5,    187,    158,      4,     22,     39,     19,     30,\n",
       "           191,      8,    107,    111,     99,     16,     11,     87,\n",
       "           144,      4,     11,     12,      3,     75,     31,     17,\n",
       "             5,    243,     51,     34,    177,    168,   2612,      2],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,    337,     15,     13,     11,    948,\n",
       "            12,     28,    277,    126,     10,     35,     70,      4,\n",
       "           879,    180,      2,      3,   2085,   5505,     10,     33,\n",
       "         10330,     10,   4338,     32,     46,    110,    883,     35,\n",
       "             3,     61,     39,     19,    124,    539,      3,    211,\n",
       "            44,      6,      3,    399,     14,     33,      7,   5710,\n",
       "          2257,     32,      6,     33,    516,     80,   5312,      3,\n",
       "           324,     32,     27,    105,     53,    661,   2477,      8,\n",
       "            59,   1252,    787,     28,   2136,    152,      2,      3,\n",
       "          1472,   1453,    488,     38,     33,  18200,   2031,   4571,\n",
       "            70,     21,      0,     32,      4,     33,     70,     10,\n",
       "             3,      0,     32,      4,      6,     33, 152657,     32,\n",
       "            46,      0,  56561,     10,  18200,   5497,     44,     30,\n",
       "            35,    431,   1186,     29,  18423,    948,     12,    337,\n",
       "           126,      4,    318,      3,     96,     10,     11,   5166,\n",
       "            21,    117,     46,      5,     27,     26,    301,      3,\n",
       "         70508,    948,      4,     36,      5,    169,     26,    158,\n",
       "            16,    253,     44,      4,      6,     88,     39,     19,\n",
       "           124,    130,    539,      3,    211,      4,      9,     51,\n",
       "            34,    177,    828,      3,    215,      8,    107,   2821,\n",
       "           360,      5,     93,    186,      9,     52,    264,      2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
    "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
    "\n",
    "batch_size = 400\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptropism",
   "language": "python",
   "name": "deeptropism"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
